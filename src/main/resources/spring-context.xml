<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xmlns:hdp="http://www.springframework.org/schema/hadoop"
       xmlns:batch="http://www.springframework.org/schema/batch"
       xmlns:util="http://www.springframework.org/schema/util"
       xmlns:context="http://www.springframework.org/schema/context"
       xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd
       http://www.springframework.org/schema/hadoop http://www.springframework.org/schema/hadoop/spring-hadoop.xsd
       http://www.springframework.org/schema/batch http://www.springframework.org/schema/batch/spring-batch-2.1.xsd
       http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util.xsd
       http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd">

    <context:property-placeholder  location="app.properties"/>

    <hdp:configuration id="hadoopConfiguration" properties-location="classpath:app.properties"/>

    <hdp:pig-factory exec-type="LOCAL" configuration-ref="hadoopConfiguration" properties-location="classpath:app.properties"/>

    <batch:job-repository id="jobRepository"
                          data-source="dataSource"
                          transaction-manager="transactionManager"
                          isolation-level-for-create="SERIALIZABLE"
                          table-prefix="batch_"
                          max-varchar-length="1000"
            />

    <bean id="jobLauncher" class="org.springframework.batch.core.launch.support.SimpleJobLauncher">
        <property name="jobRepository" ref="jobRepository"/>
    </bean>

    <hdp:pig-template/>

    <bean id="aggByUrl" class="pig.experiments.pigprocessors.ExecuteGeneralScript" >
        <property name="pigTemplate" ref="pigTemplate" />
        <property name="sciptName" value="classpath:pig/slow_pages.pig" />
        <property name="inputPath" value="${pig.script.input.prefix}" />
        <property name="outputPat" value="${pig.script.urlagg.output.prefix}" />
    </bean>

    <!-- Batch -->
    <batch:job id="pigJob" job-repository="jobRepository">
        <batch:step id="prepareData" next="processData">
            <batch:tasklet ref="prepare-script-tasklet"/>
        </batch:step>
        <batch:step id="processData">
            <batch:tasklet ref="aggByUrl"/>
        </batch:step>
    </batch:job>

    <!-- groovy script that push data to timed directory (preparation step) -->
    <hdp:script-tasklet id="prepare-script-tasklet" >
        <hdp:script language="groovy" evaluate="IF_MODIFIED">
            // fsh - FileSystem instance based on 'hadoopConfiguration' bean
            // jobParamaters = job parameters from spring batch
            print #{jobParameters['WorkingHour']}
        </hdp:script>
    </hdp:script-tasklet>

    <bean id="dataSource" class="org.enhydra.jdbc.pool.StandardPoolDataSource"
          destroy-method="shutdown">
        <constructor-arg index="0">
            <ref bean="outConnectionDataSource"/>
        </constructor-arg>
        <property name="maxSize" value="10"/>
        <property name="minSize" value="5"/>
    </bean>

    <!-- datasources configurations -->
    <bean id="outConnectionDataSource"
          class="org.enhydra.jdbc.standard.StandardConnectionPoolDataSource"
          destroy-method="shutdown">
        <property name="driverName" value="${db.out.driver}"/>
        <property name="url" value="${db.out.connection}"/>
    </bean>

    <bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager">
        <property name="dataSource" ref="dataSource"/>
    </bean>

</beans>